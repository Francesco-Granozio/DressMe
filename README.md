# DressMe (Demo) ğŸ‘—

A simple, nonâ€‘production demo app that uses OpenAIâ€™s GPT Vision to analyze what the device camera sees (e.g., a Tâ€‘shirt, jeans, etc.) and generates short styling advice. The advice is both displayed on screen and spoken aloud using natural Textâ€‘toâ€‘Speech.

This projectâ€™s goal is to quickly exercise OpenAI Vision and Speech APIs in a minimal, interactive SwiftUI app.

## What it does âœ¨

- Live camera preview ğŸ“·
- Oneâ€‘tap scan of the current frame sent to OpenAI Vision (`gpt-4o-mini`) ğŸ–¼ï¸ğŸ¤–
- Short, practical styling advice in English (displayed and spoken) ğŸ’¡ğŸ—£ï¸
- Simple chat screen to ask followâ€‘up questions ğŸ’¬

## Technologies used ğŸ§°

- SwiftUI for UI ğŸ“±
- AVFoundation (AVCaptureSession for camera, AVAudioPlayer for audio playback) ğŸ¥
- OpenAI APIs ğŸ§ :
  - Vision via Chat Completions with image input (`gpt-4o-mini`) ğŸ–¼ï¸
  - Textâ€‘toâ€‘Speech (`gpt-4o-mini-tts`) for a natural English voice ğŸ—£ï¸
- URLSession for networking ğŸŒ

## Setup ğŸš€

1. Requirements ğŸ› ï¸: Xcode 16+, iOS 17+ device (recommended) or Simulator.
2. Add your OpenAI API key ğŸ”‘ to the run scheme (kept local, not committed):
   - Product â†’ Scheme â†’ Edit Schemeâ€¦ â†’ Run â†’ Arguments â†’ Environment Variables
   - Add `OPENAI_API_KEY = <your_key>`
3. Camera permission ğŸ“¸: the app requests camera access at runtime.
4. Build & run â–¶ï¸ on a real device for the best experience.

> â„¹ï¸ Note: This is a demo; not productionâ€‘ready code.

---

## Demo Walkthrough ğŸ¬

ğŸ“‚ Assets live under `DressMe/Demo/`. Below are the key moments.

### 1) Initial screen (camera + actions) ğŸ“·

Shows the live camera preview, a button to scan the current frame, a mute button to stop speech, and a chat button to open conversation.

<img src="./DressMe/Demo/pre_scan.jpg" alt="Initial screen" width="360">

### 2) Processing state â³

After tapping Scan, the UI shows a loading state while the app uploads the current frame to the model and waits for the response.

<img src="./DressMe/Demo/processing.jpg" alt="Processing" width="360">

### 3) Speaking advice ğŸ—£ï¸

The model returns a short styling tip; it is displayed and spoken aloud using natural TTS.

<img src="./DressMe/Demo/speaking.jpg" alt="Speaking" width="360">

### 4) Opening chat ğŸ’¬

Tapping the chat button presents a simple chat where you can type a message to ask for followâ€‘up advice.

<img src="./DressMe/Demo/chatting.jpg" alt="Chat open" width="360">

### 5) Chat response âœ…

The modelâ€™s text response is shown in the chat as a concise, practical suggestion.

<img src="./DressMe/Demo/chat_response.jpg" alt="Chat response" width="360">

---

## Demo video ğŸ¥

https://github.com/Francesco-Granozio/DressMe/blob/main/DressMe/Demo/demo_video.mp4

*Note: The video above shows the complete demo walkthrough of the DressMe app in action.*

---

## Notes ğŸ“

- The app reads `OPENAI_API_KEY` from the environment at launch.
- For voice output, it tries OpenAI TTS first and falls back to the onâ€‘device English voice if needed.
- Network calls and model choices are tuned for demo responsiveness, not production scale or cost.
